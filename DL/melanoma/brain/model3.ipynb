{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7879386,"sourceType":"datasetVersion","datasetId":4624463}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import seaborn as sns\nimport cv2\nimport os\nimport pandas as pd\nimport os\nimport numpy as np\nimport torch\nimport glob\nimport torch.nn as nn\nfrom torchvision.transforms import transforms\nfrom torch.utils.data import DataLoader\nfrom torch.optim import Adam\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader, random_split\nfrom torch.utils.data import DataLoader\nfrom torchvision.models import resnet18\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.utils import make_grid\nimport torchvision.models as models\nimport torchvision.transforms.functional as F\nfrom PIL import Image\nimport torchvision\nimport pathlib\nimport pandas as pd\nimport numpy as np\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\nimport torch\nfrom torch.autograd import Variable\nfrom torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\nfrom torch.optim import Adam, SGD\nfrom torchvision.datasets import ImageFolder\nfrom torchvision import datasets\nimport warnings\nimport random\nimport matplotlib.image as mpimg\nwarnings.filterwarnings(\"ignore\")\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-01T18:23:15.876858Z","iopub.execute_input":"2024-04-01T18:23:15.877763Z","iopub.status.idle":"2024-04-01T18:23:20.111064Z","shell.execute_reply.started":"2024-04-01T18:23:15.877730Z","shell.execute_reply":"2024-04-01T18:23:20.110297Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Set the device for training\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-04-01T18:23:20.140070Z","iopub.execute_input":"2024-04-01T18:23:20.140385Z","iopub.status.idle":"2024-04-01T18:23:20.150169Z","shell.execute_reply.started":"2024-04-01T18:23:20.140361Z","shell.execute_reply":"2024-04-01T18:23:20.149309Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"data_transforms = transforms.Compose([\n    transforms.Resize((150, 150)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5,0.5,0.5], \n                        [0.5,0.5,0.5])\n])\n\ntrain_path = ('/kaggle/input/brain-tumor/brain-tumor/Training/')\ntest_path = ('/kaggle/input/brain-tumor/brain-tumor/Testing/')\n\ntrain_loader=DataLoader(\n    torchvision.datasets.ImageFolder(train_path,transform=data_transforms),\n    batch_size=32, shuffle=True\n)\ntest_loader=DataLoader(\n    torchvision.datasets.ImageFolder(test_path,transform=data_transforms),\n    batch_size=32, shuffle=False\n)\n\ntrain_count=len(glob.glob(train_path+'/**/*.jpg'))\ntest_count=len(glob.glob(test_path+'/**/*.jpg'))","metadata":{"execution":{"iopub.status.busy":"2024-04-01T18:23:21.217132Z","iopub.execute_input":"2024-04-01T18:23:21.217759Z","iopub.status.idle":"2024-04-01T18:23:22.673431Z","shell.execute_reply.started":"2024-04-01T18:23:21.217725Z","shell.execute_reply":"2024-04-01T18:23:22.672629Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"model = models.resnet18(pretrained=True)\n\nfor param in model.parameters():\n    param.requires_grad = False\n\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 2)  \n\nmodel.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-01T18:23:23.305670Z","iopub.execute_input":"2024-04-01T18:23:23.306023Z","iopub.status.idle":"2024-04-01T18:23:23.679238Z","shell.execute_reply.started":"2024-04-01T18:23:23.305993Z","shell.execute_reply":"2024-04-01T18:23:23.678299Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=2, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\nbest_accuracy_3 = 0.0\ncriterion = nn.CrossEntropyLoss()\ntr_losses = []\ntest_losses = []\naccuracies_train = []\naccuracies_test = []\n\nfor epoch in range(25):\n    model.train()\n    train_accuracy = 0.0\n    train_loss = 0.0\n\n    for images, labels in train_loader:\n        if torch.cuda.is_available():\n            images=Variable(images.cuda())\n            labels=Variable(labels.cuda())\n        \n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n        _,prediction=torch.max(outputs.data,1)\n        \n        train_accuracy+=int(torch.sum(prediction==labels.data))\n        \n    train_accuracy=train_accuracy/train_count\n    tr_losses.append(train_loss)\n    accuracies_train.append(train_accuracy)\n    \n    \n    model.eval()\n    test_loss = 0.0\n    test_accuracy=0.0\n    for i, (images,labels) in enumerate(test_loader):\n        if torch.cuda.is_available():\n            images=Variable(images.cuda())\n            labels=Variable(labels.cuda())\n            \n        test_loss += loss.item() \n        outputs=model(images)\n        _,prediction=torch.max(outputs.data,1)\n        test_accuracy+=int(torch.sum(prediction==labels.data))\n    \n    test_accuracy=test_accuracy/test_count\n    test_loss /= len(test_loader)\n    accuracies_test.append(test_accuracy)\n    \n    \n    print('Epoch: '+str(epoch+1)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n    \n    if test_accuracy>best_accuracy_3:\n        torch.save(model,'best_checkpoint.model')\n        best_accuracy_3=test_accuracy\n\n     ","metadata":{"execution":{"iopub.status.busy":"2024-04-01T18:23:29.150939Z","iopub.execute_input":"2024-04-01T18:23:29.151828Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch: 1 Train Loss: 49.21602430567145 Train Accuracy: 0.8997871295234976 Test Accuracy: 0.9028465346534653\nEpoch: 2 Train Loss: 28.700463134795427 Train Accuracy: 0.9474373669559522 Test Accuracy: 0.9108910891089109\nEpoch: 3 Train Loss: 25.318361384794116 Train Accuracy: 0.9546422138529557 Test Accuracy: 0.9195544554455446\nEpoch: 4 Train Loss: 24.577586797997355 Train Accuracy: 0.9561159325364336 Test Accuracy: 0.9226485148514851\nEpoch: 5 Train Loss: 22.910403043031693 Train Accuracy: 0.9590633699033896 Test Accuracy: 0.9220297029702971\nEpoch: 6 Train Loss: 22.548049012199044 Train Accuracy: 0.9590633699033896 Test Accuracy: 0.9220297029702971\nEpoch: 7 Train Loss: 21.28906859550625 Train Accuracy: 0.9618470607499591 Test Accuracy: 0.9257425742574258\nEpoch: 8 Train Loss: 21.922990329563618 Train Accuracy: 0.9608645816276404 Test Accuracy: 0.9127475247524752\nEpoch: 9 Train Loss: 20.16784937866032 Train Accuracy: 0.9626657933518913 Test Accuracy: 0.9418316831683168\nEpoch: 10 Train Loss: 19.461330781690776 Train Accuracy: 0.9652857376780744 Test Accuracy: 0.9263613861386139\nEpoch: 11 Train Loss: 19.266806667670608 Train Accuracy: 0.9646307515965286 Test Accuracy: 0.9405940594059405\nEpoch: 12 Train Loss: 19.31967204157263 Train Accuracy: 0.9672506959227116 Test Accuracy: 0.9331683168316832\nEpoch: 13 Train Loss: 19.617880544625223 Train Accuracy: 0.9633207794334371 Test Accuracy: 0.9375\n","output_type":"stream"}]},{"cell_type":"code","source":"print(best_accuracy_3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(tr_losses, label='Training Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training Loss over Epochs')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(accuracies_train, label='Acc_train')\nplt.plot(accuracies_test, label='Acc_test')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Accuracy over Epochs')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}